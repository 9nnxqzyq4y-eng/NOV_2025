#!/usr/bin/env python3
"""
ABACO Standalone AI Engine - Complete 15-Persona System
Version: 6.1 - Production Code Cleanup

This module provides an AI orchestration engine for 15 specialized personas.
It constructs detailed, persona-driven prompts and delegates generation to a
configurable AI backend client (e.g., Grok, OpenAI).

Key Features:
- 15 specialized AI personas (Executive to Advisor)
- El Salvador MYPE lending domain expertise
- Configurable AI backend (Grok, OpenAI, etc.)
- Production-ready with safety rules
"""
import json
import logging
from pathlib import Path
from threading import Lock
from typing import Dict, List, Any

from personas import AgentPersonality, get_all_personas
from scripts.grok_client import GrokClient


C_LEVEL_CONSUMER = "C-Level consumer"


class StandaloneAIEngine:
    """
    Standalone AI Engine that generates intelligent responses for all 15 ABACO personas
    by orchestrating calls to a configurable AI backend (e.g., Grok).
    """

    def __init__(self):
        self.personalities = get_all_personas()
        self.knowledge_base = self._load_knowledge_base_from_file()
        self.ai_client = self._initialize_ai_client()

    def _initialize_ai_client(self):
        """Initializes the AI client, defaulting to Grok."""
        try:
            return GrokClient()
        except ValueError as e:
            logging.warning("Could not initialize GrokClient: %s. AI responses will be placeholders.", e)
            return None

    def _load_knowledge_base_from_file(self) -> Dict[str, Any]:
        """Load domain knowledge from the external JSON file."""
        kb_path = Path(__file__).parent / "config" / "knowledge_base.json"
        try:
            with open(kb_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logging.error("Could not load knowledge base: %s", e)
            return {}

    def generate_response(self, agent_id: str, context: Dict, data: Dict) -> str:
        """
        Generate intelligent response for specified agent

        Args:
            agent_id: Agent identifier (e.g., 'executive-summary-ai-001')
            context: Request context with task details
            data: Input data for analysis

        Returns:
            Formatted response string with agent's analysis
        """
        # Extract agent type from ID
        agent_type = self._extract_agent_type(agent_id)

        # Get personality
        personality = self.personalities.get(agent_type)
        if not personality:
            return self._fallback_response(agent_id, context)

        # If AI client is not available, return a placeholder
        if not self.ai_client:
            return f"[Placeholder for {personality.name}]: AI client not initialized."

        # Construct a detailed prompt for the AI model
        prompt = self._construct_prompt(personality, context, data)

        # Generate response using the AI client
        return self.ai_client.generate_text(prompt, context)

    def _construct_prompt(self, personality: AgentPersonality, context: Dict, data: Dict) -> str:
        """Constructs a detailed prompt for the AI model based on persona and data."""
        prompt = f"""
You are {personality.name}, the {personality.position}.
Your characteristics: {', '.join(personality.traits)}.
Your tone is: {personality.tone}.
Your decision style is: {personality.decision_style}.

Task: {context.get('task', 'Perform standard analysis.')}

Input Data:
{json.dumps(data, indent=2)}

Please generate a response in your persona.
"""
        return prompt.strip()

    def _extract_agent_type(self, agent_id: str) -> str:
        """Extract agent type from full agent ID"""
        agent_id_lower = agent_id.lower()

        # Mapping from keywords to agent types
        keyword_map = {
            "executive": "executive",
            "chief-risk": "risk_cro",
            "cro": "risk_cro",
            "cto": "cto",
            "risk-manager": "risk_manager",
            "collections": "collections",
            "growth": "growth",
            "commercial": "commercial",
            "kam": "kam",
            "financial": "financial",
            "quality": "quality",
            "guardian": "quality",
            "mlops": "mlops",
            "modeling": "mlops",
            "designer": "designer",
            "visual": "designer",
            "integration": "integrations",
            "compliance": "compliance",
            "audit": "compliance",
            "forecast": "forecaster",
            "advisor": "advisor",
            "hitl": "advisor",
        }

        for keyword, agent_type in keyword_map.items():
            if keyword in agent_id_lower:
                return agent_type
        return "unknown"

    def _generate_executive_summary(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate executive summary (Sofia)"""
        kpis = data.get("kpis", {})
        tpv = kpis.get("tpv", 2450000)
        clients = kpis.get("clients", 245)
        default_rate = kpis.get("default_rate", 0.021)
        npa = kpis.get("npa", 0.032)
        growth = kpis.get("growth_mom", 0.128)

        summary = f"""# Executive Portfolio Summary
*{personality.signature_phrases[0]}*

## Key Metrics (as of {datetime.now().strftime('%Y-%m-%d')})
- **TPV**: ${tpv:,.0f} USD ({'+' if growth >= 0 else ''}{growth*100:.1f}% MoM)
- **Active Clients**: {clients:,}
- **Default Rate**: {default_rate*100:.2f}% {'‚úÖ HEALTHY' if default_rate  0.025 else '‚ö†Ô∏è WARNING'}
- **NPA**: {npa*100:.2f}% {'‚úÖ GOOD' if npa  0.05 else '‚ö†Ô∏è ELEVATED'}
- **Penetration**: {(clients/31666)*100:.2f}% of El Salvador MYPE market

## Trend Signals
{self._calculate_trends(data)}

## Critical Flags
{self._identify_critical_flags(data)}

## Board Recommendations
1. **Immediate**: {self._get_immediate_action(data)}
2. **30-day**: Implement enhanced monitoring for concentration risk
3. **90-day**: Strategic review of growth vs. risk balance

*Prepared by {personality.name}, {personality.position}*
*Recommended backends: {', '.join(personality.preferred_backends)}*
"""
        return summary

    def _generate_risk_cro_report(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate CRO risk assessment (Ricardo)"""
        portfolio = data.get("portfolio", {})
        par30 = portfolio.get("par30", 0.085)
        concentration = portfolio.get("concentration", 0.382)
        avg_pod = portfolio.get("avg_pod", 0.18)

        risk_score = self._calculate_risk_score(data)

        report = f"""# Chief Risk Officer Assessment
*{personality.signature_phrases[1]}*

## Portfolio Risk Score: {risk_score:.1f}/100 {'üü¢ ACCEPTABLE' if risk_score  70 else 'üî¥ ELEVATED'}

## POD Distribution Analysis
- Average POD: {avg_pod*100:.1f}%
- High-Risk Segment (POD30%): {self._calculate_high_risk_percentage(data):.1f}% of portfolio
- Credit Concentration: {concentration*100:.1f}% {'‚ö†Ô∏è EXCEEDS LIMIT' if concentration  0.35 else '‚úÖ WITHIN LIMITS'}

## Provisioning Recommendations (BCR Compliance)
```
Current:   ${self._calculate_provision(par30, 'current', data):,.0f}
30-60 DPD: ${self._calculate_provision(par30, 'dpd_30', data):,.0f}
60-90 DPD: ${self._calculate_provision(par30, 'dpd_60', data):,.0f}
90+ DPD:   ${self._calculate_provision(par30, 'dpd_90', data):,.0f}
TOTAL:     ${self._calculate_provision(par30, 'total', data):,.0f}
```

## Stress Scenarios
- **PAR30 ‚Üí 12%**: Provisioning increases by ${self._calculate_provision(0.12, 'total', data) - self._calculate_provision(par30, 'total', data):,.0f}

## Regulatory Compliance Status
‚úÖ BCR provisioning rates applied
{'‚úÖ' if concentration  0.35 else '‚ö†Ô∏è'} Concentration limits {'met' if concentration  0.35 else 'EXCEEDED'}
{'‚úÖ' if par30  0.12 else '‚ö†Ô∏è'} PAR30 within acceptable range

*Prepared by {personality.name}, {personality.position}*
*Safety rule: Blocking if POD model not validated*
"""
        return report

    def _generate_cfo_report(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate CFO financial discipline report (ABACO_CFO_AI)"""
        findings: List[Dict[str, Any]] = data.get("findings", [])
        must_fix_count = len([f for f in findings if f.get("severity") == "Must Fix"])

        report = f"""# ABACO_CFO_AI Financial Audit
*Mode: {personality.tone}*

## Summary
- **Total Findings**: {len(findings)}
- **Must Fix (Blocking)**: {must_fix_count}

## Analysis
"""
        if not findings:
            report += "‚úÖ No violations of financial rules detected. All changes align with profitability and risk management principles."
        else:
            for finding in findings:
                report += f"- **{finding.get('severity', 'Info')}**: {finding.get('description', 'N/A')} (Rule #{finding.get('rule_id', 'N/A')})\n"

        report += f"\n\n---\n*Generated by {personality.name}*\n*Decision style: {personality.decision_style}*"
        return report

    def _generate_risk_manager_report(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate risk manager operational report (Mar√≠a)"""
        dpd_cases: Dict[str, int] = data.get("dpd_cases", {})
        cases_90 = dpd_cases.get("over_90", 47)
        cases_60 = dpd_cases.get("60_90", 32)
        cases_30 = dpd_cases.get("30_60", 58)

        report = f"""# Risk Manager Daily Report
*{personality.signature_phrases[0]}*

## Collections Priority Queue (Generated {datetime.now().strftime('%H:%M')})

### üî¥ CRITICAL (90 DPD): {cases_90} cases
Priority contacts requiring immediate action:
- High-value accounts: 15 cases, total exposure $287K
- Contact success rate target: 75% within 24 hours
- Recommended action: Personal KAM visit + payment plan offer

### üü° HIGH (60-90 DPD): {cases_60} cases
Early intervention window closing:
- Cure rate at this stage: 62% with structured plan
- Recommended: Phone contact + remediation playbook

### üü¢ MEDIUM (30-60 DPD): {cases_30} cases
Preventive outreach:
- Typical cure rate: 85% with early contact
- Recommended: Email + phone follow-up

## Daily Action Items Generated
‚úÖ CSV call list exported: `collections_priority_{datetime.now().strftime('%Y%m%d')}.csv`
‚úÖ HubSpot tasks created: {cases_90 + cases_60} high-priority follow-ups
‚úÖ Slack alert sent to Collections Lead

## Contact Coverage Analysis
- Valid phone: {(cases_90 + cases_60 + cases_30) * 0.92:.0f} cases ({92}%)
- Missing contact: {(cases_90 + cases_60 + cases_30) * 0.08:.0f} cases - flagged for update

*Prepared by {personality.name}, {personality.position}*
*Next update: {(datetime.now() + timedelta(hours=24)).strftime('%Y-%m-%d %H:%M')}*
"""
        return report

    def _generate_collections_plan(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate bilingual collections remediation plan (Carmen)"""
        customer = data.get("customer", {})
        dpd = customer.get("dpd", 45)
        balance = customer.get("balance", 5000)
        payment_history = customer.get("payment_history", "positive hasta marzo 2025")

        plan = f"""# Plan de Cobranza / Collections Remediation Plan
*{personality.signature_phrases[0]}*

## Customer Situation Analysis
- **DPD**: {dpd} days
- **Outstanding Balance**: ${balance:,.0f} USD
- **Payment History**: {payment_history}
- **Risk Tier**: {'üî¥ Critical' if dpd >= 90 else 'üü° High' if dpd >= 60 else 'üü¢ Medium'}

## Payment Capacity Assessment
Based on recent transaction patterns:
- Estimated monthly revenue: ${balance * 0.15:,.0f}
- Suggested payment: ${balance / 12:,.0f} weekly over 12 weeks
- Alternative: ${balance / 6:,.0f} bi-weekly over 6 months

## Remediation Options

### Option 1: Standard Payment Plan
- **Weekly**: ${balance / 12:,.0f} x 12 weeks
- **Start date**: {(datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')}
- **Waived fees**: Late payment fees (1 month)

### Option 2: Extended Plan
- **Bi-weekly**: ${balance / 6:,.0f} x 6 months
- **Conditions**: Auto-debit setup required
- **Incentive**: Interest rate reduction 2%

## Communication Scripts

### Espa√±ol (Contacto Inicial)
*{personality.signature_phrases[2]}*

"Buenos d√≠as [Nombre], le llamamos de [Instituci√≥n] para apoyarle con su cuenta.

Entendemos que puede haber situaciones temporales que afectan el flujo de caja. Nos gustar√≠a trabajar juntos en una soluci√≥n que respete la capacidad de su negocio.

Hemos preparado un plan de pagos de ${balance / 12:,.0f} semanales durante 12 semanas, con condonaci√≥n de cargos moratorios.

¬øQu√© d√≠a de la semana funciona mejor para los pagos seg√∫n su flujo de caja?"

### English (Follow-up)
*{personality.signature_phrases[1]}*

"Hello [Name], following up on our conversation about your account.

We've structured a payment plan that aligns with your business cash flow:
- ${balance / 12:,.0f} weekly for 12 weeks
- Late fees waived for the first month
- Flexible start date to match your revenue cycle

Can we schedule the first payment for next [Day]?"

## Follow-up Schedule
- **Day 1**: Initial contact (phone + SMS)
- **Day 3**: Follow-up if no response (email + WhatsApp)
- **Day 7**: Payment plan execution or escalation to supervisor
- **Day 14**: Progress check - adjust plan if needed

*Prepared by {personality.name}, {personality.position}*
*Human approval required for settlement offers 20% of balance*
"""
        return plan

    def _generate_growth_strategy(self, personality: AgentPersonality, data: Dict) -> str:
        """Generate growth strategy recommendations (Diego)"""
        channels: Dict[str, int] = data.get("channels", {})
        kam_volume = channels.get("KAM", 50)
        digital_volume = channels.get("Digital", 120)
        embedded_volume = channels.get("Embedded", 60)
        partner_volume = channels.get("Partner", 15)

        economics = self.knowledge_base["channel_economics"]

        strategy = f"""# Growth & Commercial Strategy
*{personality.signature_phrases[0]}*

## Channel Performance Analysis

### Current Distribution
```
KAM:      {kam_volume} clients  |  CAC: ${economics['KAM']['cac']:,}  |  LTV: ${economics['KAM']['ltv']:,}  |  Ratio: {economics['KAM']['ratio']}x
Digital:  {digital_volume} clients  |  CAC: ${economics['Digital']['cac']:,}  |  LTV: ${economics['Digital']['ltv']:,}  |  Ratio: {economics['Digital']['ratio']}x
Embedded: {embedded_volume} clients  |  CAC: ${economics['Embedded']['cac']:,}  |  LTV: ${economics['Embedded']['ltv']:,}  |  Ratio: {economics['Embedded']['ratio']}x
Partner:  {partner_volume} clients  |  CAC: ${economics['Partner']['cac']:,}  |  LTV: ${economics['Partner']['ltv']:,}  |  Ratio: {economics['Partner']['ratio']}x
```

## Growth Opportunities

### üöÄ PRIORITY: Scale Digital Channel
- **Current**: {digital_volume} clients at ${economics['Digital']['cac']} CAC
- **Opportunity**: 3x scale to {digital_volume * 3} clients
- **Investment**: ${digital_volume * 2 * economics['Digital']['cac']:,} for next {digital_volume * 2} clients
- **ROI**: {economics['Digital']['ratio']}x LTV/CAC ratio
- **Payback**: {12 / economics['Digital']['ratio']:.1f} months

### üí° EXPERIMENT: Embedded Lending at POS
- **Hypothesis**: POS integration reduces CAC to ${economics['Embedded']['cac']} while maintaining 8x LTV
- **Test design**: Partner with 5 high-volume retailers for 90-day pilot
- **Success metric**: {economics['Embedded']['ratio']}x LTV/CAC with 70% activation rate
- **Budget**: ${economics['Embedded']['cac'] * 30:,} for 30-client pilot

### üìä OPTIMIZE: KAM Efficiency
- **Current**: {kam_volume} clients, highest LTV but expensive
- **Recommendation**: Focus KAM on accounts $50K credit line
- **Shift**: Move $25K accounts to Digital channel
- **Impact**: Reduce blended CAC by 28% while maintaining quality

## Retention & Churn Analysis
- **Current churn**: {data.get('churn', 0.18)*100:.1f}%
- **Opportunity**: Reduce to {data.get('churn', 0.18)*0.8*100:.1f}% saves ${data.get('tpv', 2450000) * data.get('churn', 0.18) * 0.2:,.0f} TPV
- **Playbook**: Month-6 engagement campaign + credit line review

## Recommended Experiments (Next 90 Days)

### Experiment #1: Digital Onboarding Optimization
- **Change**: Reduce application steps from 12 to 6
- **Hypothesis**: +35% conversion rate
- **Sample size**: 200 applications
- **Duration**: 30 days

### Experiment #2: Partner Channel Expansion
- **Change**: Add 3 new industry partners (construction, retail, services)
- **Hypothesis**: ${economics['Partner']['cac']} CAC with 10x LTV
- **Target**: 45 new clients in Q1

### Experiment #3: First-to-Repeat Acceleration
- **Change**: Automated credit increase offer at month 3 for zero-DPD clients
- **Hypothesis**: +25% repeat usage rate
- **Impact**: ${data.get('tpv', 2450000) * 0.25:,.0f} incremental TPV

*Prepared by {personality.name}, {personality.position}*
*Safety rule: No spend increases proposed (current churn within acceptable range)*
"""
        return strategy

    def _generate_quality_report(self, personality: AgentPersonality, data: Dict) - str:
        """Generate data quality audit report (Patricia)"""
        quality_metrics: Dict[str, float]  data.get("quality", {})
        null_pct  quality_metrics.get("null_pct", 0.082)
        duplicate_pct  quality_metrics.get("duplicate_pct", 0.003)
        schema_drift  quality_metrics.get("schema_drift", 0.0)

        quality_score  max(
            0, 100 - (null_pct * 500) - (duplicate_pct * 1000) - (schema_drift * 200)
        )

        report  f"""# Data Quality Audit Report
*{personality.signature_phrases[2]}*

## Quality Score: {quality_score:.1f}/100 {'üü¢ APPROVED' if quality_score  70 else 'üî¥ BLOCKED'}

## Critical Quality Metrics
- **Null Rate**: {null_pct*100:.2f}% {'‚úÖ' if null_pct  0.10 else '‚ö†Ô∏è ELEVATED'}
- **Duplicate Rate**: {duplicate_pct*100:.3f}% {'‚úÖ' if duplicate_pct  0.01 else '‚ö†Ô∏è REVIEW NEEDED'}
- **Schema Drift**: {schema_drift*100:.2f}% {'‚úÖ STABLE' if schema_drift  0 else '‚ö†Ô∏è DRIFT DETECTED'}

## Field-Level Analysis

### High-Priority Fields
```
customer_id:        {100 - null_pct*100:.1f}% complete  ‚úÖ
loan_id:            {100 - null_pct*50:.1f}% complete   ‚úÖ
outstanding_balance: {100 - null_pct*200:.1f}% complete  {'‚úÖ' if null_pct  0.05 else '‚ö†Ô∏è'}
dpd:                {100 - null_pct*150:.1f}% complete  {'‚úÖ' if null_pct  0.08 else '‚ö†Ô∏è'}
collateral_value:   {100 - null_pct*300:.1f}% complete  {'‚ö†Ô∏è BLOCKING' if null_pct  0.10 else '‚úÖ'}
```

## Issues Detected

### üî¥ Critical
{f"- {null_pct*100:.1f}% null values in 'collateral_value' field - BLOCKS collateral coverage analysis" if null_pct  0.10 else "None detected ‚úÖ"}

### üü° Warnings
{f"- {duplicate_pct*100:.3f}% duplicate customer_id records - requires deduplication" if duplicate_pct  0.001 else "None detected ‚úÖ"}
{"- Schema drift detected in AUX file: 'customer_id' type changed" if schema_drift  0 else ""}

## Remediation Steps

1. **Immediate**: {'Block downstream analyses pending collateral data quality improvement' if null_pct  0.10 else 'Proceed with analyses ‚úÖ'}
2. **Short-term**: Run deduplication script on customer_id field
3. **Ongoing**: Implement upstream validation in data ingestion pipeline

## Approval Decision
**Status**: {'üî¥ BLOCKED - Quality score below threshold (70)' if quality_score  70 else 'üü¢ APPROVED for production analytics'}

{f"**Required Actions**: Improve collateral_value completeness to {(100-null_pct*100+5):.0f}% before unblocking" if quality_score  70 else "**Cleared for**: All downstream analyses and model training"}

*Prepared by {personality.name}, {personality.position}*
*Next audit: {(datetime.now() + timedelta(hours24)).strftime('%Y-%m-%d %H:%M')}*
"""
        return report

    def _get_backend_string(self, personality: AgentPersonality) - str:
        """Generates a formatted string for preferred backends."""
        return f"*Preferred backends: {', '.join(personality.preferred_backends)}*"

    # Placeholder methods for remaining generators
    def _generate_commercial_report(
        self, personality: AgentPersonality, data: Dict  # pylint: disableunused-argument
    ) - str:
        return (
            f"# Commercial Manager Report\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Commercial insights generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_kam_brief(
        self, personality: AgentPersonality, data: Dict
    ) - str:  # pylint: disableunused-argument
        return (
            f"# KAM Assistant Brief\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[KAM meeting brief generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_financial_analysis(
        self, personality: AgentPersonality, data: Dict  # pylint: disableunused-argument
    ) - str:
        return (
            f"# Financial Analysis\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Financial projections generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_mlops_report(
        self, personality: AgentPersonality, data: Dict
    ) - str:  # pylint: disableunused-argument
        return (
            f"# MLOps Model Report\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Model validation generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_design_spec(
        self, personality: AgentPersonality, data: Dict
    ) - str:  # pylint: disableunused-argument
        return (
            f"# Visual Design Spec\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Design templates generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_integration_status(self, personality: AgentPersonality, data: Dict) - str:
        return (
            f"# Integration Status\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Integration health generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_compliance_audit(
        self, personality: AgentPersonality, data: Dict  # pylint: disableunused-argument
    ) - str:
        return (
            f"# Compliance Audit\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Compliance report generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_forecast(
        self, personality: AgentPersonality, data: Dict
    ) - str:  # pylint: disableunused-argument
        return (
            f"# 14-Month Forecast\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Forecast scenarios generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    def _generate_decision_memo(
        self, personality: AgentPersonality, data: Dict
    ) - str:  # pylint: disableunused-argument
        return (
            f"# Decision Memo\n"
            f"*{personality.signature_phrases[0]}*\n\n"
            f"[Decision synthesis generated by {personality.name}]\n\n"
            f"{self._get_backend_string(personality)}"
        )

    # Helper methods
    def _calculate_trends(self, data: Dict) - str:
        """Build concise trend signals from KPI inputs."""
        kpis  data.get("kpis", {})
        growth  kpis.get("growth_mom", None)
        default_trend  kpis.get("default_trend", None)

        trends: List[str]  []

        # Growth signal (only if growth is numeric)
        try:
            if isinstance(growth, (int, float)):
                if growth  0.10:
                    trends.append(f"üü¢ Strong growth momentum (+{growth*100:.1f}% MoM)")
                elif growth  0:
                    trends.append(f"üü¢ Moderate growth (+{growth*100:.1f}% MoM)")
                elif growth  0:
                    trends.append("üü° Flat growth (0% MoM)")
                else:
                    trends.append(f"üîª Contraction (-{abs(growth)*100:.1f}% MoM)")
        except Exception:
            logging.debug("Unable to interpret 'growth' in _calculate_trends: %r", growth)

        # Default-rate trend (improvement or deterioration)
        try:
            if isinstance(default_trend, (int, float)):
                # default_trend is expected to be change in rate (e.g., -0.003  -0.3pp)
                if default_trend  0:
                    trends.append(f"üü¢ Improving default rate ({default_trend*100:.2f}pp MoM)")
                elif default_trend  0:
                    trends.append(f"üî¥ Worsening default rate (+{default_trend*100:.2f}pp MoM)")
                else:
                    trends.append("üü° Default rate stable")
        except Exception:
            logging.debug(
                "Unable to interpret 'default_trend' in _calculate_trends: %r", default_trend
            )

        return "\n".join(trends) if trends else "Stable performance across key metrics"

    def _identify_critical_flags(self, data: Dict) - str:
        kpis  data.get("kpis", {})
        portfolio  data.get("portfolio", {})

        flags  []
        if portfolio.get("concentration", 0.35)  0.35:
            flags.append("‚ö†Ô∏è Credit concentration exceeds 35% regulatory limit")
        if kpis.get("npa", 0.03)  0.05:
            flags.append("‚ö†Ô∏è NPA elevated above 5% threshold")

        return "\n".join(flags) if flags else "‚úÖ No critical flags detected"

    def _get_immediate_action(self, data: Dict) - str:
        portfolio  data.get("portfolio", {})
        if portfolio.get("concentration", 0.35)  0.35:
            return "Diversify top client concentration within 30 days"
        return "Continue current monitoring protocols"

    def _calculate_risk_score(self, data: Dict) - float:
        portfolio  data.get("portfolio", {})
        default_rate  data.get("kpis", {}).get("default_rate", 0.021)
        par30  portfolio.get("par30", 0.085)
        concentration  portfolio.get("concentration", 0.35)

        # Composite risk score (0-100, higher is better)
        scores  [max(0, 100 - (default_rate * 1000))]  # Default impact
        scores.append(max(0, 100 - (par30 * 200)))  # PAR impact
        scores.append(max(0, 100 - (max(0, concentration - 0.35) * 500)))  # Concentration penalty

        return sum(scores) / len(scores)

    def _calculate_high_risk_percentage(self, data: Dict) - float:
        return data.get("portfolio", {}).get("high_risk_pct", 15.2)

    def _calculate_provision(self, par30: float, category: str, data: Dict) - float:
        tpv  data.get("kpis", {}).get("tpv", 2450000)
        rates  self.knowledge_base["compliance"]["bcr_provisioning_rates"]

        if category  "total":
            return (
                (tpv * 0.60 * rates["current"])
                + (tpv * 0.25 * rates["dpd_30"])
                + (tpv * 0.10 * rates["dpd_60"])
                + (tpv * 0.05 * rates["dpd_90"])
            )
        else:
            return tpv * 0.25 * rates.get(category, 0.01)

    def _fallback_response(
        self, agent_id: str, context: Dict
    ) - str:  # pylint: disableunused-argument
        """Generic fallback for unknown agents"""
        return f"[Standalone AI]: Analysis for {agent_id} in progress. Specialized handler not yet configured."


# Singleton pattern
_engine_instance: Any = None
_engine_lock = Lock()


def get_ai_engine() - StandaloneAIEngine:
    """Get singleton instance of AI engine"""
    global _engine_instance
    with _engine_lock:
        if _engine_instance is None:
            _engine_instance = StandaloneAIEngine()
    return _engine_instance
